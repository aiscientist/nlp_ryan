{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 0. Data Loading and processing\n",
    "앞선 실험에서 TfidfVectorizer를 사용하는 것이 근소하게 성능이 더 좋았기 때문에, 여기서는 TfidfVectorizer만 사용하였음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load training set and test set\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "newsgroups_test  = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "X_train = newsgroups_train.data\n",
    "Y_train = newsgroups_train.target\n",
    "X_test  = newsgroups_test.data\n",
    "Y_test  = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Declare two vectorizers\n",
    "# count_vectorizer = CountVectorizer(min_df=40)\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Fitting vectorizers to the training set\n",
    "# count_vectorizer = count_vectorizer.fit(X_train)\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform X_train and X_test using 2 vectorizers\n",
    "# X_train_count = count_vectorizer.transform(X_train)\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "# X_test_count  = count_vectorizer.transform(X_test)\n",
    "X_test_tfidf  = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrix into dense matrix\n",
    "X_train = X_train_tfidf.toarray()\n",
    "X_test = X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = Y_train.shape[0]\n",
    "num_test = Y_test.shape[0]\n",
    "\n",
    "print(\"Number of training points: \", num_train)\n",
    "print(\"Number of test points: \", num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim_X = X_train.shape[1]\n",
    "print(\"Dimension of X: %d\" % dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = np.unique(Y_test)\n",
    "print(\"Labels: \", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 1. Fitting classifiers with TF-IDF vectorizer and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Placeholder\n",
    "- Shape of the placeholder for inputs: [batch_size, dim_X]\n",
    "- Shape of the placeholder for outputs: [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dim_X], name=\"Inputs\")\n",
    "Y = tf.placeholder(tf.int32, [None], name=\"Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Build the model\n",
    "- TF-Slim을 이용하여 아주 간단하게 모델을 선언해봅시다.\n",
    "- https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fully_connected(inputs, num_labels, hidden_sizes=[100, 100], scope='FCN'):\n",
    "    \"\"\"\n",
    "    [fully_connected] n개의 hidden layer를 갖는 feed-forward network 생성 (with TF-Slim)\n",
    "    \n",
    "    [Args]\n",
    "      - inputs: 입력 데이터를 위한 placeholder\n",
    "      - hidden_sizes: a list (은닉 노드 수를 원하는 층 수 만큼 기록한 리스트)\n",
    "      - Scope: default value (\"FCN\")\n",
    "    \"\"\"\n",
    "    # Inputs에서 1차원의 텐서들이 placeholder로 들어온다고 가정\n",
    "    input_dim = inputs.get_shape()[1]\n",
    "\n",
    "    # Number of hidden layers\n",
    "    num_hidden_layers = len(hidden_sizes)\n",
    "    \n",
    "    with slim.arg_scope([slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                        biases_initializer=tf.constant_initializer(0.0)):\n",
    "        net = inputs\n",
    "        for i in range(num_hidden_layers):\n",
    "            scope_name = 'fc' + str(i)\n",
    "            net = slim.fully_connected(inputs=net, num_outputs=hidden_sizes[i], scope=scope_name)\n",
    "        net = slim.fully_connected(inputs=net, num_outputs=num_labels, activation_fn=None, scope='logits')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logits = fully_connected(inputs=X, num_labels=len(labels), hidden_sizes=[100, 100], scope='FCN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Predicting operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.nn.in_top_k(logits, Y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_EPOCHS = 40\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 결과를 저장할 리스트를 생성\n",
    "train_cost_list = list()\n",
    "test_cost_list = list()\n",
    "test_accuracy_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Variable initialization\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Indices for constructing batches\n",
    "    start_idx = range(0, num_train, BATCH_SIZE)\n",
    "    end_idx = range(BATCH_SIZE, num_train + 1, BATCH_SIZE)\n",
    "    \n",
    "    NUM_BATCHES = len(start_idx)\n",
    "    \n",
    "    for epoch in range(0,NUM_EPOCHS):\n",
    "\n",
    "        # Set \"train_cost\" as 0 before starting the epoch\n",
    "        train_cost = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for start, end in zip(start_idx, end_idx):\n",
    "\n",
    "            # Construct the input batch\n",
    "            batch_xs = X_train[start:end]\n",
    "            batch_ys = Y_train[start:end]\n",
    "            \n",
    "            # Calculate cost\n",
    "            tmp_cost, _ = sess.run([cost, train_op], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            train_cost += tmp_cost\n",
    "        \n",
    "        train_cost = train_cost / NUM_BATCHES\n",
    "        train_cost_list.append(train_cost)\n",
    "        print(\"[{} epoch] training cost {:0.4f}\".format((epoch + 1), train_cost))\n",
    "        \n",
    "        # Validation phase\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            test_cost, test_accuracy = sess.run([cost, accuracy], feed_dict={X: X_test, Y: Y_test})\n",
    "            test_cost_list.append(test_cost)\n",
    "            test_accuracy_list.append(test_accuracy)\n",
    "            print(\"\\t[{} epoch] test accuracy {:0.4f}\".format((epoch + 1), test_accuracy))\n",
    "            \n",
    "    # Test phase\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: X_test, Y: Y_test})\n",
    "    print(\"\\n\")\n",
    "    print(\"Test accuracy: {:0.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
