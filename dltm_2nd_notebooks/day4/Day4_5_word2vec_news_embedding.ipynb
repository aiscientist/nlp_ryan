{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Day4_3_visualization.ipynb 에서 단어를 custom_tokenizer를 한 다음, 문서 벡터로 표현하여 그대로 시각화 방법을 이용하여 2차원 벡터로 학습하였습니다. \n",
    "\n",
    "이 경우에는 말미에 언급한 것처럼 노이즈한 결과가 나오기도 합니다. 시각화는 대상을 좋은 벡터로 표현한 다음에 (representation learning), 이를 저차원의 벡터로 다시 한 번 압축해야 합니다. \n",
    "\n",
    "대부분의 단어/문서 시각화는 Word2Vec / Doc2Vec / Glove / RNN / RBM 등으로 질 좋은 고차원 벡터의 representation을 얻은 뒤, 이를 다시 한 번 2차원 벡터로 압축하고 있습니다. 한 번에 풀리는 건 없습니다. 특히나 시각화와 같이 노이즈에 민감한 작업에서는 더 그러합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "이번에는 4_3과 동일한 문서에 대하여 토크나이징을 하지 않은 체로 어절을 그대로 Word2Vec 학습을 하겠습니다. 데이터의 숫자가 정말로 풍부하고, 모델이 수많은 어절을 그대로 학습할 수 있을만큼의 하드웨어라면, 어절을 그대로 Word2Vec 학습하여도 그 결과는 충분히 쓸만합니다만, 그 목적이 다를 수 있습니다. 아래에서 그 예시를 살펴보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213087"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_fname = '../../../data/corpus_10days/news/2016-10-24_article_all_normed.txt'\n",
    "word2vec_fname = '../../../data/corpus_10days/models/2016-10-24_news_word2vec_model.pkl'\n",
    "\n",
    "TRAIN_WORD2VEC = True\n",
    "\n",
    "import sys\n",
    "sys.path.append('../mypy/')\n",
    "\n",
    "from corpus import Corpus\n",
    "corpus = Corpus(corpus_fname, iter_sent=True)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "doublespace line spliter이기 때문에 Word2VecCorpus는 '  '를 기준으로 doc을 sents로 나눈 뒤, 각 sent를 다시 한 번 split()하여 word list로 yield 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['의원', '60명', '내무장관에게', '서한', '철거', '때', '어린이', '안전', '신경', '써야']\n",
      "['보호자', '없는', '아동', '난민', '70명은', '영국에', '도착']\n",
      "['22일', '경찰에', '돌', '던지는', '칼레', '난민', '연합뉴스']\n",
      "['파리', '런던', '연합뉴스', '박성진', '황정우', '특파원', '프랑스', '칼레', '난민촌', '철거를', '이틀', '앞둔', '22일', '현지시간', '난민촌', '주변에서', '현지', '경찰과', '난민이', '충돌했다고', '현지', '프랑스앵포가', '보도했다']\n",
      "['난민촌', '철거에', '반대하는', '난민', '50명가량은', '경찰을', '향해', '유리병과', '돌을', '던졌으며', '경찰은', '연막탄을', '쏘면서', '이들을', '해산했다']\n",
      "['이', '과정에서', '별다른', '부상자는', '나오지', '않았다']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "    \n",
    "class Word2VecCorpus:\n",
    "    \n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        if not os.path.isfile(fname):\n",
    "            print('File not found: %s' % fname)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='utf-8') as f:\n",
    "            for doc in f:\n",
    "                for sent in doc.strip().split('  '):\n",
    "                    sent = sent.strip()\n",
    "                    if not sent:\n",
    "                        continue\n",
    "                    yield sent.split()\n",
    "                \n",
    "                \n",
    "word2vec_corpus = Word2VecCorpus(corpus_fname)\n",
    "\n",
    "for num_sent, sent in enumerate(word2vec_corpus):\n",
    "    if num_sent > 5: break\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "if TRAIN_WORD2VEC:\n",
    "    word2vec_model = Word2Vec(word2vec_corpus, min_count=30)\n",
    "    with open(word2vec_fname, 'wb') as f:\n",
    "        pickle.dump(word2vec_model, f)\n",
    "        \n",
    "else:\n",
    "    with open(word2vec_fname, 'rb') as f:\n",
    "        word2vec_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "gensim.__version__ = 0.13.x 기준으로, Word2Vec.syn0에는 단어 벡터가 저장되어 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18329"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_words = ['김무성', \n",
    "              '박근혜', \n",
    "              '문재인', \n",
    "              '국방부', \n",
    "              '정부', \n",
    "              '국정원', \n",
    "              '대통령', \n",
    "              '축구', \n",
    "              '외교', \n",
    "              '정책', \n",
    "              '군대', \n",
    "              '미국', \n",
    "              '일본', \n",
    "              '중국'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "어절만 이용하여 학습했음에도 불구하고, 김무성의 유사어로 정치인들이 등장함을 볼 수 있습니다. 이는 뉴스 코퍼스에서는 정치인의 이름만 적고 띄어쓰기를 하는 경우도 충분하기 때문입니다. \n",
    "\n",
    "하지만 '김무성 - 대표도'와 같은 유사 어절이 등장한 것은, 뉴스에서 '김무성'으로만 적는 경우와 '김무성 대표도'로 적는 경우가 혼재되어 있어서, '대표도'의 문맥이 '김무성'의 문맥과 유사하였기 때문입니다. \n",
    "\n",
    "비슷한 의미로, 박근혜 - 박 (6251)의 경우에는 '박근혜 대통령', '박 대통령'이 번갈아가며 이용되었기 때문입니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "그러나, 국정원의 경우에는 총 42번 나왔으며, min_count=30으로 하였기 때문에 18000여개의 단어 중에서는 infrequent 한 편에 속합니다. 그리고 이 때의 유사 어절들은 문맥상 잘 어울리지 않는 어절들입니다. \n",
    "\n",
    "    Vocab(count:42, index:12945, sample_int:4294967296)\n",
    "    국정원 - 단국대 (33) (0.774)\n",
    "    국정원 - 대우학원 (34) (0.726)\n",
    "    국정원 - 김형수 (92) (0.722)\n",
    "    국정원 - 인터뷰가 (36) (0.717)\n",
    "    국정원 - 입 (59) (0.711)\n",
    "    국정원 - 정동구 (31) (0.709)\n",
    "    국정원 - 정유라씨가 (41) (0.705)\n",
    "    국정원 - 취재진이 (33) (0.703)\n",
    "    국정원 - 크리스 (33) (0.696)\n",
    "    국정원 - 이사장을 (81) (0.696)\n",
    "    \n",
    "Word2Vec에서는 infrequent 한 단어(어절)들의 유사 단어(어절)들은 infrequent 한 경향이 있습니다. 빈도수가 충분하지 않을 경우에는 학습이 잘 되지 않는 것이라고 해석할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "어절을 그대로 학습할 경우에는, 아래와 같이 대통령의 유사어절로 '대통령 + 조사'의 어절들이 자주 등장합니다. \n",
    "    \n",
    "    Seed word = 대통령\n",
    "    Vocab(count:3411, index:89, sample_int:4294967296)\n",
    "    대통령 - 대통령의 (3074) (0.809)\n",
    "    대통령 - 대통령을 (287) (0.784)\n",
    "    대통령 - 대통령과 (437) (0.784)\n",
    "    대통령 - 대통령에 (255) (0.723)\n",
    "    대통령 - 대통령은 (2852) (0.716)\n",
    "    대통령 - 대통령에게 (203) (0.708)\n",
    "    대통령 - 대통령도 (125) (0.704)\n",
    "    대통령 - 대통령이다 (54) (0.698)\n",
    "    대통령 - 대통령이 (5054) (0.698)\n",
    "    대통령 - 정부에서 (76) (0.687)\n",
    "    \n",
    "우리가 원하는 것이 Language model을 학습하는 것이라면, 이 결과는 유용합니다. 하지만, 우리가 문맥적으로 유사한 단어들을 찾기 위하여 Word2Vec을 학습하는 것이 목적이었다면, 어절을 그대로 학습하는 것보다 토크나이징을 한 뒤, 이를 이용하여 학습해야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Seed word = 김무성\n",
      "Vocab(count:332, index:1413, sample_int:4294967296)\n",
      "김무성 - 김종인 (165) (0.935)\n",
      "김무성 - 오세훈 (72) (0.920)\n",
      "김무성 - 안철수 (345) (0.916)\n",
      "김무성 - 손학규 (270) (0.895)\n",
      "김무성 - 대표도 (106) (0.887)\n",
      "김무성 - 유승민 (160) (0.877)\n",
      "김무성 - 천정배 (36) (0.866)\n",
      "김무성 - 최경환 (43) (0.866)\n",
      "김무성 - 정의화 (35) (0.850)\n",
      "김무성 - 김부겸 (100) (0.819)\n",
      "\n",
      "\n",
      "Seed word = 박근혜\n",
      "Vocab(count:4420, index:62, sample_int:4294967296)\n",
      "박근혜 - 이승만 (36) (0.753)\n",
      "박근혜 - 박 (6251) (0.735)\n",
      "박근혜 - 마두로 (46) (0.712)\n",
      "박근혜 - 박정희 (216) (0.708)\n",
      "박근혜 - 국정과 (37) (0.701)\n",
      "박근혜 - 뒤늦은 (30) (0.688)\n",
      "박근혜 - 민생에 (38) (0.679)\n",
      "박근혜 - 나서달라고 (59) (0.655)\n",
      "박근혜 - 두테르테 (218) (0.654)\n",
      "박근혜 - 요청했고 (73) (0.653)\n",
      "\n",
      "\n",
      "Seed word = 문재인\n",
      "Vocab(count:940, index:392, sample_int:4294967296)\n",
      "문재인 - 손학규 (270) (0.883)\n",
      "문재인 - 비서실장이 (97) (0.869)\n",
      "문재인 - 문 (932) (0.855)\n",
      "문재인 - 안철수 (345) (0.851)\n",
      "문재인 - 김종인 (165) (0.850)\n",
      "문재인 - 장관의 (162) (0.803)\n",
      "문재인 - 송민순 (663) (0.798)\n",
      "문재인 - 대표가 (1013) (0.789)\n",
      "문재인 - 급급한 (39) (0.788)\n",
      "문재인 - 김무성 (332) (0.787)\n",
      "\n",
      "\n",
      "Seed word = 국방부\n",
      "Vocab(count:247, index:2008, sample_int:4294967296)\n",
      "국방부 - 외교부 (391) (0.889)\n",
      "국방부 - 차관급 (38) (0.864)\n",
      "국방부 - 노동당 (63) (0.857)\n",
      "국방부 - 부부장 (63) (0.854)\n",
      "국방부 - 외무성 (74) (0.852)\n",
      "국방부 - 국무부 (95) (0.830)\n",
      "국방부 - 윤병세 (80) (0.827)\n",
      "국방부 - 류 (148) (0.819)\n",
      "국방부 - 케리 (33) (0.814)\n",
      "국방부 - 장일훈 (31) (0.813)\n",
      "\n",
      "\n",
      "Seed word = 정부\n",
      "Vocab(count:1769, index:194, sample_int:4294967296)\n",
      "정부 - 정부의 (814) (0.818)\n",
      "정부 - 정부가 (1017) (0.735)\n",
      "정부 - 법인세 (212) (0.730)\n",
      "정부 - 정부는 (1002) (0.706)\n",
      "정부 - 경제민주화 (97) (0.693)\n",
      "정부 - 정부에서 (76) (0.693)\n",
      "정부 - 법안 (79) (0.687)\n",
      "정부 - 국민투표 (80) (0.684)\n",
      "정부 - 법인세율 (56) (0.683)\n",
      "정부 - 시진핑 (120) (0.679)\n",
      "\n",
      "\n",
      "Seed word = 국정원\n",
      "Vocab(count:42, index:12945, sample_int:4294967296)\n",
      "국정원 - 단국대 (33) (0.774)\n",
      "국정원 - 대우학원 (34) (0.726)\n",
      "국정원 - 김형수 (92) (0.722)\n",
      "국정원 - 인터뷰가 (36) (0.717)\n",
      "국정원 - 입 (59) (0.711)\n",
      "국정원 - 정동구 (31) (0.709)\n",
      "국정원 - 정유라씨가 (41) (0.705)\n",
      "국정원 - 취재진이 (33) (0.703)\n",
      "국정원 - 크리스 (33) (0.696)\n",
      "국정원 - 이사장을 (81) (0.696)\n",
      "\n",
      "\n",
      "Seed word = 대통령\n",
      "Vocab(count:3411, index:89, sample_int:4294967296)\n",
      "대통령 - 대통령의 (3074) (0.809)\n",
      "대통령 - 대통령을 (287) (0.784)\n",
      "대통령 - 대통령과 (437) (0.784)\n",
      "대통령 - 대통령에 (255) (0.723)\n",
      "대통령 - 대통령은 (2852) (0.716)\n",
      "대통령 - 대통령에게 (203) (0.708)\n",
      "대통령 - 대통령도 (125) (0.704)\n",
      "대통령 - 대통령이다 (54) (0.698)\n",
      "대통령 - 대통령이 (5054) (0.698)\n",
      "대통령 - 정부에서 (76) (0.687)\n",
      "\n",
      "\n",
      "Seed word = 축구\n",
      "Vocab(count:43, index:12742, sample_int:4294967296)\n",
      "축구 - 쉐보레 (30) (0.864)\n",
      "축구 - 크루즈 (53) (0.850)\n",
      "축구 - 오픈마켓 (30) (0.842)\n",
      "축구 - 전통의 (35) (0.836)\n",
      "축구 - 거장 (31) (0.830)\n",
      "축구 - 기획한 (54) (0.829)\n",
      "축구 - 패밀리 (43) (0.825)\n",
      "축구 - 주인도네시아 (32) (0.821)\n",
      "축구 - 강사 (41) (0.820)\n",
      "축구 - 부문에 (51) (0.816)\n",
      "\n",
      "\n",
      "Seed word = 외교\n",
      "Vocab(count:166, index:3124, sample_int:4294967296)\n",
      "외교 - 국방 (71) (0.884)\n",
      "외교 - 통일 (88) (0.799)\n",
      "외교 - 한미 (96) (0.789)\n",
      "외교 - 양국 (120) (0.789)\n",
      "외교 - 사드 (72) (0.781)\n",
      "외교 - 북핵 (204) (0.767)\n",
      "외교 - 한일 (78) (0.763)\n",
      "외교 - 제재 (104) (0.750)\n",
      "외교 - 안보 (361) (0.747)\n",
      "외교 - 배치 (93) (0.742)\n",
      "\n",
      "\n",
      "Seed word = 정책\n",
      "Vocab(count:445, index:1016, sample_int:4294967296)\n",
      "정책 - 개혁 (118) (0.863)\n",
      "정책 - 개편 (263) (0.836)\n",
      "정책 - 정책을 (306) (0.808)\n",
      "정책 - 방안이 (120) (0.796)\n",
      "정책 - 정부와 (255) (0.795)\n",
      "정책 - 규제 (345) (0.794)\n",
      "정책 - 정책으로 (32) (0.793)\n",
      "정책 - 제도 (223) (0.790)\n",
      "정책 - 경제 (1278) (0.789)\n",
      "정책 - 규제를 (122) (0.785)\n",
      "\n",
      "\n",
      "Seed word = 미국\n",
      "Vocab(count:3311, index:92, sample_int:4294967296)\n",
      "미국 - 미국의 (601) (0.791)\n",
      "미국 - 중국 (2527) (0.788)\n",
      "미국 - 러시아 (229) (0.762)\n",
      "미국 - 영국 (668) (0.760)\n",
      "미국 - 미 (598) (0.746)\n",
      "미국 - 브렉시트 (124) (0.713)\n",
      "미국 - 미국과 (215) (0.702)\n",
      "미국 - 유럽 (412) (0.696)\n",
      "미국 - 일본 (1661) (0.692)\n",
      "미국 - 중국의 (344) (0.690)\n",
      "\n",
      "\n",
      "Seed word = 일본\n",
      "Vocab(count:1661, index:209, sample_int:4294967296)\n",
      "일본 - 중국 (2527) (0.822)\n",
      "일본 - 러시아 (229) (0.784)\n",
      "일본 - 영국 (668) (0.782)\n",
      "일본 - 유럽 (412) (0.767)\n",
      "일본 - 미국과 (215) (0.758)\n",
      "일본 - 중국과 (125) (0.738)\n",
      "일본 - 대만 (143) (0.732)\n",
      "일본 - 프랑스 (662) (0.731)\n",
      "일본 - 한국과 (200) (0.728)\n",
      "일본 - 일본의 (342) (0.727)\n",
      "\n",
      "\n",
      "Seed word = 중국\n",
      "Vocab(count:2527, index:134, sample_int:4294967296)\n",
      "중국 - 일본 (1661) (0.822)\n",
      "중국 - 미국 (3311) (0.788)\n",
      "중국 - 유럽 (412) (0.770)\n",
      "중국 - 러시아 (229) (0.751)\n",
      "중국 - 중국의 (344) (0.738)\n",
      "중국 - 미국과 (215) (0.732)\n",
      "중국 - 중국과 (125) (0.723)\n",
      "중국 - 중국에 (127) (0.693)\n",
      "중국 - 영국 (668) (0.690)\n",
      "중국 - 상하이 (114) (0.682)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    if (word in word2vec_model.vocab) == False:\n",
    "        continue\n",
    "        \n",
    "    print('\\n\\nSeed word = %s' % word)\n",
    "    print(word2vec_model.vocab[word])\n",
    "    for similar_word, sim in word2vec_model.most_similar(word):\n",
    "        print('%s - %s (%d) (%.3f)' % (word, \n",
    "                                       similar_word, \n",
    "                                       word2vec_model.vocab[similar_word].count, \n",
    "                                       sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
