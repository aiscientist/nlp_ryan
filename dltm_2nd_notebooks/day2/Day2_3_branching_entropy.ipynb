{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "corpus_fname = '../../../data/corpus_10days/news/2016-10-28_article_all_normed.txt'\n",
    "\n",
    "max_l_length = 6\n",
    "max_r_length = 5\n",
    "min_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176597"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from corpus import Corpus\n",
    "corpus = Corpus(corpus_fname, iter_sent=True)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Branching Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Branching Entropy 역시 문장 단위로 for loop을 돌면서 subword가 어떻게 branching 하는지 카운트를 하면 됩니다. \n",
    "\n",
    "L은 '어린 --> 어린이'처럼 오른쪽에 어떤 글자가 등장하는지 카운트 하는 dict_dict 입니다. \n",
    "R은 '어린이 <-- 린이'처럼 왼쪽에 어떤 글자가 등장하는지 카운트 하는 dict_dict 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isnerting 175000 sents... "
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "L = defaultdict(lambda: defaultdict(lambda: 0)) # 어린 --> 어린이\n",
    "R = defaultdict(lambda: defaultdict(lambda: 0)) # 어린이 <-- 린이\n",
    "\n",
    "for num_sent, sent in enumerate(corpus):\n",
    "    \n",
    "    if num_sent % 5000 == 0:\n",
    "        sys.stdout.write('\\risnerting %d sents... ' % num_sent)\n",
    "        \n",
    "    for token in sent.split():\n",
    "        \n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "    \n",
    "        for e in range(2, min(max_l_length, len(token)) + 1):\n",
    "            subword_from = token[:e-1]\n",
    "            subword_to = token[:e]\n",
    "            L[subword_from][subword_to] += 1\n",
    "            \n",
    "        for b in range(2, min(max_r_length + 1, len(token))):\n",
    "            subword_from = token[-b+1:]\n",
    "            subword_to = token[-b:]\n",
    "            R[subword_from][subword_to] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "av_l = 0 if not word in R else len(R[word])는 word가 R에 존재하지 않는 경우에는 0을 할당하고, word가 R에 존재한다면 R[word]를 가져온 뒤, 해당 dict의 길이를 av_l 값으로 할당하라는 의미입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근\t(0, 7)\n",
      "박근혜\t(5, 23)\n",
      "국방\t(1, 24)\n",
      "국방부\t(1, 13)\n",
      "국방부는\t(0, 0)\n",
      "국방장\t(0, 1)\n",
      "국방장관\t(0, 7)\n",
      "트와이\t(0, 1)\n",
      "트와이스\t(0, 8)\n"
     ]
    }
   ],
   "source": [
    "def get_accessor_variety(word):\n",
    "    \n",
    "    # av_l: ?-린이\n",
    "    # av_r: 어린-?\n",
    "    \n",
    "    av_l = 0 if not word in R else len(R[word])\n",
    "    av_r = 0 if not word in L else len(L[word])\n",
    "    return (av_l, av_r)\n",
    "\n",
    "\n",
    "for word in ['박근', '박근혜', '국방', '국방부', '국방부는', '국방장', '국방장관', '트와이', '트와이스']:\n",
    "    av = get_accessor_variety(word)\n",
    "    print('%s\\t(%d, %d)' % (word, av[0], av[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Branching Entropy는 단어의 경계 부분에서 entropy가 증가합니다. \n",
    "\n",
    "    국방\t(-0.000, 1.097)\n",
    "    국방부\t(-0.000, 1.601)\n",
    "    국방부는\t(0.000, 0.000)\n",
    "    국방장\t(0.000, -0.000)\n",
    "    국방장관\t(0.000, 1.575)\n",
    "    \n",
    "'국방' 다음에는 여러 단어가 올 수 있기 때문에 right-side entropy가 1.097입니다. 하지만 '국방장' 다음에는 반드시 '-관'이 나타나서 '국방장관'이 되었기 때문에 right-side entropy가 0임을 볼 수 있습니다. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "박근\t(0.000, 0.082)\n",
      "박근혜\t(1.523, 2.305)\n",
      "국방\t(-0.000, 1.097)\n",
      "국방부\t(-0.000, 1.601)\n",
      "국방부는\t(0.000, 0.000)\n",
      "국방장\t(0.000, -0.000)\n",
      "국방장관\t(0.000, 1.575)\n",
      "트와이\t(0.000, -0.000)\n",
      "트와이스\t(0.000, 1.313)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_branching_entropy(word):\n",
    "    \n",
    "    def entropy(extensions):\n",
    "        '''extensions: dict[str]: int\n",
    "        '''\n",
    "        sum_ = sum(extensions.values())\n",
    "        if sum_ == 0:\n",
    "            return 0\n",
    "        \n",
    "        entropy = 0\n",
    "        for v in extensions.values():\n",
    "            if v == 0: continue\n",
    "            prob = v / sum_\n",
    "            entropy += (prob * np.log(prob))\n",
    "        return -1 * entropy\n",
    "\n",
    "    # be_l: ?-린이\n",
    "    # be_r: 어린-?\n",
    "    \n",
    "    be_l = 0 if not word in R else entropy(R[word])\n",
    "    be_r = 0 if not word in L else entropy(L[word])    \n",
    "    return (be_l, be_r)\n",
    "\n",
    "\n",
    "for word in ['박근', '박근혜', '국방', '국방부', '국방부는', '국방장', '국방장관', '트와이', '트와이스']:\n",
    "    be = get_branching_entropy(word)\n",
    "    print('%s\\t(%.3f, %.3f)' % (word, be[0], be[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Entropy가 높은 subword는 단어일 가능성이 높습니다. 왜냐하면 좌/우에 등장할 다른 단어들의 종류가 다양하기 때문입니다. \n",
    "\n",
    "그렇기 때문에 길이가 1인 글자의 entropy는 항상 높습니다. 그래서 길이가 1인 L들은 큰 의미를 지니지 못합니다. 또한 의미를 알아볼 수 있는 길이가 1인 L의 단어는 그리 많지 않으니까요. 하지만 조사/어미 같은 경우에는 길이가 1인 경우가 많습니다. 그래서 left-side entropy 역시 매우 높게 나타납니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "은\t(4.807, 2.379)\n",
      "는\t(3.736, 1.895)\n",
      "이\t(4.952, 4.214)\n",
      "가\t(4.386, 3.724)\n",
      "에게\t(3.507, 1.024)\n",
      "에서\t(4.818, 0.539)\n"
     ]
    }
   ],
   "source": [
    "for word in ['은', '는', '이', '가', '에게', '에서']:\n",
    "    be = get_branching_entropy(word)\n",
    "    print('%s\\t(%.3f, %.3f)' % (word, be[0], be[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Tokenizer with Cohesion and Branching entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Cohesion probability는 interior word scoring 방법이며, Branching entropy는 exterior word scoring 방법입니다. L_tokenizer를 cohesion만의 관점이 아니라 cohesion과 branching entropy를 함께 이용할 수도 있습니다. 단어의 경계가 더 강조될 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserting subwords into L: done\n",
      "num subword = 578867\n",
      "num subword = 30922 (after pruning with min count 30)\n"
     ]
    }
   ],
   "source": [
    "from cohesion import CohesionProbability\n",
    "cohesion_probability = CohesionProbability()\n",
    "cohesion_probability.train(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "sorted 함수는 key를 두 개를 이용할 수 있습니다. \n",
    "\n",
    "    key=lambda x:(x[1], x[2])\n",
    "    \n",
    "위 구문은 x라는 item이 들어오면 1차 기준으로 x[1]을 이용하고, x[1]이 같을 경우 x[2]를 이용하라는 의미입니다. reverse=True이므로 x[1]이 큰 순서대로 정렬되며, x[1]이 같을 경우에는 x[2]가 같은 순서대로 정렬됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청와대 --> 청와대\n",
      "\n",
      "청와대는 --> 청와대\n",
      "\n",
      "민정수석 --> 민정수석\n",
      "\n",
      "민정수석이 --> 민정수석\n",
      "\n",
      "공연을 --> 공연\n",
      "\n",
      "공연하게 --> 공연\n",
      "\n",
      "박근혜 --> 박근혜\n",
      "\n",
      "박근혜의 --> 박근혜\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cpbe_tokenize(word):\n",
    "    if (not word) or (len(word) <= 2):\n",
    "        return word\n",
    "    \n",
    "    score = []\n",
    "    for e in range(2, min(len(word), max_l_length)+1):\n",
    "        subword = word[:e]\n",
    "        be_l, be_r = get_branching_entropy(subword)\n",
    "        cp_l = cohesion_probability.get_cohesion(subword)\n",
    "        score.append((subword, cp_l * be_r, e)) # (word, cohesion * branching entropy, length)\n",
    "        \n",
    "    return sorted(score, key=lambda x:(x[1], x[2]), reverse=True)[0][0]\n",
    "\n",
    "for word in ['청와대', '청와대는', '민정수석', '민정수석이', '공연을', '공연하게', '박근혜', '박근혜의']:\n",
    "    print('%s --> %s\\n' % (word, cpbe_tokenize(word)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
