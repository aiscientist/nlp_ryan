{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feed-forward neural network (version 2)\n",
    "- a.k.a. Multi-Layer Perceptrons (MLP), Fully-connected network\n",
    "- 다른 방식으로 네트워크를 구성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 0. Load MNIST data\n",
    "- 이번에는 one_hot=False로 데이터를 불러와봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one_hot=False\n",
    "mnist = input_data.read_data_sets(\"MNIST_idx3/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_trn, Y_trn = mnist.train.images, mnist.train.labels\n",
    "X_val, Y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, Y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(Y_trn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_trn = Y_trn.shape[0]\n",
    "num_val = Y_val.shape[0]\n",
    "num_test = Y_test.shape[0]\n",
    "\n",
    "print(\"Number of training points: \", num_trn)\n",
    "print(\"Number of validation points: \", num_val)\n",
    "print(\"Number of test points: \", num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim_X = X_trn.shape[1]\n",
    "pixel_X = int(np.sqrt(dim_X)) # np.sqrt의 출력이 float32이므로, 이를 int 자료형으로 변경\n",
    "# dim_Y = Y_trn.shape[1]\n",
    "\n",
    "print(\"Dimension of X: %d (%d x %d)\" % (dim_X, pixel_X, pixel_X))\n",
    "# print(\"Dimension of Y: \", dim_Y)\n",
    "print(\"Dimension of Y: None.. Y is a array of integers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Build the graph\n",
    "Tensorflow에서는 모델을 'graph'로 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.1. Placeholder for inputs and outputs\n",
    "- Shape of the placeholder for inputs: [batch_size, input_dimension]\n",
    "- Shape of the placeholder for outputs: [batch_size]\n",
    "- Placeholder의 batch_size를 None으로 하면, placeholder에 들어가기 전에 batch size를 조절해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dim_X], name=\"Inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Y = tf.placeholder(tf.int32, [None], name=\"Labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test = X.get_shape()\n",
    "# test = X.get_shape()[1]\n",
    "print(test)\n",
    "# print(type(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1.2. Build the model\n",
    "\n",
    "- Weight와 bias, 그래프 구조를 생성하는 함수를 만들어봅시다.\n",
    "- 여기에서는 2개의 hidden layers를 생성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fully_connected(inputs, hidden_dim_1, hidden_dim_2, num_classes, scope='SimpleFCN'):\n",
    "    \"\"\"\n",
    "    [fully_connected] 2개의 hidden layer를 갖는 feed-forward network 생성\n",
    "    \n",
    "    [Args]\n",
    "      - inputs: 입력 데이터를 위한 placeholder\n",
    "      - hidden_dim_1: 첫 번째 은닉층의 노드 수\n",
    "      - hidden_dim_2: 두 번째 은닉층의 노드 수\n",
    "      - num_classes: 예측하고자 하는 클래스의 수 (= 출력층의 노드 수))\n",
    "      - Scope: default value (\"SimpleFCN\")\n",
    "    \"\"\"\n",
    "    # Inputs에서 1차원의 텐서들이 placeholder로 들어온다고 가정\n",
    "    input_dim = inputs.get_shape()[1]\n",
    "    \n",
    "    # tf.truncated_normal_initializer의 형태를 간소화\n",
    "    trunc_normal = lambda stddev: tf.truncated_normal_initializer(mean=0.0, stddev=stddev)\n",
    "    \n",
    "    # tf.constant_initializer의 형태를 간소화\n",
    "    constant = lambda value: tf.constant_initializer(value=value)\n",
    "    \n",
    "    # Define \"end_points\"\n",
    "    end_points = {}\n",
    "    \n",
    "    with tf.variable_scope(scope):\n",
    "        with tf.variable_scope('HiddenLayer_1'):\n",
    "            W_h1 = tf.get_variable(\"weights\", [input_dim, hidden_dim_1], initializer=trunc_normal(0.1))\n",
    "            b_h1 = tf.get_variable(\"biases\", [hidden_dim_1], initializer=constant(0.0))\n",
    "            h1 = tf.nn.relu(tf.matmul(inputs, W_h1)+ b_h1, name=\"Activation\")\n",
    "            end_points['h1'] = h1\n",
    "            \n",
    "        with tf.variable_scope('hiddenLayer_2'):\n",
    "            W_h2 = tf.get_variable(\"weights\", [hidden_dim_1, hidden_dim_2], initializer=trunc_normal(0.09))\n",
    "            b_h2 = tf.get_variable(\"biases\", [hidden_dim_2], initializer=constant(0.01))\n",
    "            h2 = tf.nn.relu(tf.matmul(h1, W_h2) + b_h2, name=\"Activation\")\n",
    "            end_points['h2'] = h2\n",
    "            \n",
    "        with tf.variable_scope('OutputLayer'):\n",
    "            W_o = tf.get_variable(\"weights\", [hidden_dim_2, num_classes], initializer=trunc_normal(0.1))\n",
    "            b_o = tf.get_variable(\"biases\", [num_classes], initializer=constant(0.0))\n",
    "            with tf.variable_scope('Logits'): logits = tf.matmul(h2, W_o) + b_o\n",
    "#             logits = tf.matmul(h2, W_o) + b_o\n",
    "            end_points['logits'] = logits\n",
    "    \n",
    "    return logits, end_points\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logits, end_points = fully_connected(inputs=X, hidden_dim_1=500, hidden_dim_2=300, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Print my end points\n",
    "pprint(end_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print names of my variables\n",
    "variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='SimpleFCN')\n",
    "pprint([v.name for v in variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1. Loss function\n",
    "- Classification 문제에서 제일 많이 사용하는 loss function은 **cross-entropy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "두 가지 옵션이 있음.\n",
    "- tf.nn.softmax_cross_entropy_with_logits: Y가 one-hot encoded 되어 있을 때\n",
    "- tf.nn.sparse_softmax_cross_entropy_with_logits: Y가 class에 대한 index 값일 때)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2. Training operator\n",
    "- First, define the oprimizer. (**optimizer**)\n",
    "- And then, define training operator. (**train_op**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "자주 사용하는 optimizer로는 다음과 같은 것들이 있음.\n",
    "- tf.train.GradientDescentOptimizer\n",
    "- tf.train.AdagradOptimizer\n",
    "- tf.train.MomentumOptimizer\n",
    "- **tf.train.AdamOptimizer** (많은 연구자들이 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "자세한 사항은 [TensorFlow API_guides: Training](https://www.tensorflow.org/api_guides/python/train) 참조!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3. Predicting operator\n",
    "- correct_prediction: boolean (True or False)\n",
    "- accuracy: 먼저 correct_prediction을 float32로 변환 후에 배치 내 평균을 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**tf.nn.in_top_k(x, y, k)**\n",
    "- tf.nn.in_top_k(x, y, k)는 prediction x의 상위 k개의 결과가 true label y를 포함하는지를 계산\n",
    "- 이에 대한 output은 boolean 으로 나오므로, 이를 0, 1로 바꿔주기 위해서 tf.cast를 이용하여 float32로 변환한 이후에 accuracy를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.nn.in_top_k(logits, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(correct_prediction)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4. Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.5. Run the session\n",
    "- 앞서 만든 graph, operator 등을 돌리는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 30\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Batch 인덱스 생성\n",
    "start_idx = list(range(0, num_trn, BATCH_SIZE))\n",
    "end_idx = list(range(BATCH_SIZE, num_trn + 1, BATCH_SIZE))\n",
    "for start, end in zip(start_idx, end_idx): print(start, '\\t', end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Batch의 개수\n",
    "print(len(start_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trn_cost_list = list()\n",
    "val_cost_list = list()\n",
    "val_accuracy_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess, tf.device(\"/cpu:0\"):\n",
    "    # Variable initialization\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Indices for constructing batches\n",
    "    start_idx = range(0, num_trn, BATCH_SIZE)\n",
    "    end_idx = range(BATCH_SIZE, num_trn + 1, BATCH_SIZE)\n",
    "    \n",
    "    NUM_BATCHES = len(start_idx)\n",
    "    \n",
    "    for epoch in range(0,NUM_EPOCHS):\n",
    "\n",
    "        # Set \"trn_cost\" as 0 before starting the epoch\n",
    "        trn_cost = 0\n",
    "        \n",
    "        # Training phase\n",
    "        for start, end in zip(start_idx, end_idx):\n",
    "\n",
    "            # Construct the input batch\n",
    "            batch_xs = X_trn[start:end]\n",
    "            batch_ys = Y_trn[start:end]\n",
    "            \n",
    "            # Calculate cost\n",
    "            tmp_cost, _ = sess.run([cost, train_op], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            trn_cost += tmp_cost\n",
    "        \n",
    "        trn_cost = trn_cost / NUM_BATCHES\n",
    "        trn_cost_list.append(trn_cost)\n",
    "        print(\"[{} epoch] training cost {:0.4f}\".format((epoch + 1), trn_cost))\n",
    "        \n",
    "        # Validation phase\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            val_cost, val_accuracy = sess.run([cost, accuracy], feed_dict={X: X_val, Y: Y_val})\n",
    "            val_cost_list.append(val_cost)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            print(\"\\t[{} epoch] validation accuracy {:0.4f}\".format((epoch + 1), val_accuracy))\n",
    "            \n",
    "    # Test phase\n",
    "    test_accuracy = sess.run(accuracy, feed_dict={X: X_test, Y: Y_test})\n",
    "    print(\"\\n\")\n",
    "    print(\"Test accuracy: {:0.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
