{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras._impl.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras._impl.keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras._impl.keras.layers import Reshape, Flatten, Dropout, Concatenate, dot\n",
    "from tensorflow.python.keras._impl.keras.optimizers import Adam\n",
    "from tensorflow.python.keras._impl.keras.models import Model\n",
    "from tensorflow.python.keras._impl.keras.layers import LSTM\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras._impl.keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "\n",
    "from tensorflow.python.keras._impl.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras._impl.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv.zip  train.json.zip\r\n",
      "test.json.zip\r\n"
     ]
    }
   ],
   "source": [
    "%ls /Users/user/.kaggle/competitions/whats-cooking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '~/.kaggle/competitions/whats-cooking/train.json'\n",
    "test_path = '~/.kaggle/competitions/whats-cooking/test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_json(train_path)\n",
    "df_test = pd.read_json(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.head()\n",
    "df_train['all_ingredients'] = df_train['ingredients'].map(\";\".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#각 재료의 값들을 Labeling하는 작업\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df_train['all_ingredients'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine', 'lettuce', 'black', 'olives', 'grape', 'tomatoes', 'garlic', 'pepper', 'purple', 'onion', 'seasoning', 'garbanzo', 'beans', 'feta', 'cheese', 'crumbles', 'plain', 'flour', 'ground', 'salt', 'thyme', 'eggs', 'green', 'yellow', 'corn', 'meal', 'milk', 'vegetable', 'oil', 'mayonaise', 'cooking', 'chilies', 'grilled', 'chicken', 'breasts', 'powder', 'soy', 'sauce', 'butter', 'livers', 'water', 'wheat', 'shallots', 'cornflour', 'cayenne', 'onions', 'paste', 'lemon', 'juice', 'chili', 'passata', 'cumin', 'boneless', 'skinless', 'thigh', 'garam', 'masala', 'double', 'cream', 'natural', 'yogurt', 'bay', 'leaf', 'sugar', 'fresh', 'ginger', 'root', 'cinnamon', 'vanilla', 'extract', 'powdered', 'baking', 'olive', 'medium', 'shrimp', 'chopped', 'cilantro', 'jalapeno', 'flat', 'parsley', 'skirt', 'steak', 'white', 'vinegar', 'sea', 'chorizo', 'sausage', 'pistachio', 'nuts', 'almond', 'bark', 'dried', 'cranberries', 'pineapple', 'pork', 'poblano', 'peppers', 'tortillas', 'cheddar', 'iceberg']\n"
     ]
    }
   ],
   "source": [
    "print(list(cv.vocabulary_.keys())[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(df_train.cuisine)\n",
    "enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_dict(dataset):\n",
    "    t = Tokenizer()\n",
    "    t = t.fit_on_texts(dataset)\n",
    "    word_dict = t.word_index\n",
    "    pd_dict = pd.DataFrame(list(word_dict.items()), columns=['word', 'index'])\n",
    "#     pd_dict['word_emb'] = pd_dict['word'].map(tapi_embedding)\n",
    "    \n",
    "    return pd_dict, word_dict\n",
    "\n",
    "pd_dict, token = emb_dict(cafe_db['query'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
